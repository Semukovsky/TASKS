{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание - линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с признаками (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет из материалов к уроку или по ссылке https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv \n",
    "\n",
    "\n",
    "Описание признаков:\n",
    "\n",
    "* Agency — название страхового агентства\n",
    "* Agency Type — тип страхового агентства\n",
    "* Distribution Channel — канал продвижения страхового агентства\n",
    "* Product Name — название страхового продукта\n",
    "* Duration — длительность поездки (количество дней)\n",
    "* Destination — направление поездки\n",
    "* Net Sales — сумма продаж \n",
    "* Commission (in value) — комиссия страхового агентства\n",
    "* Gender — пол застрахованного\n",
    "* Age — возраст застрахованного\n",
    "\n",
    "Ответ:\n",
    "* Claim — потребовалась ли страховая выплата: «да» — 1, «нет» — 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработайте пропущенные значения и примените написанные функции onehot_encode() и minmax_scale().\n",
    "\n",
    "**Подсказка**: маску для категориальных признаков можно сделать фильтром cat_features_mask = (df.dtypes == \"object\").values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T19:43:10.010407Z",
     "start_time": "2025-10-21T19:43:05.905257Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "def onehot_encode(arr):\n",
    "    uniques = list(set(arr))\n",
    "    mapping = {val: i for i, val in enumerate(uniques)}\n",
    "    res = np.zeros((len(arr), len(uniques)), dtype=int)\n",
    "    for i, val in enumerate(arr):\n",
    "        res[i, mapping[val]] = 1\n",
    "    return res\n",
    "\n",
    "def minmax_scale(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "cat_mask = (df.dtypes == \"object\").values\n",
    "cat_cols = df.columns[cat_mask]\n",
    "num_cols = [c for c in df.columns if not df[c].dtype == \"object\" and c != 'Claim']\n",
    "\n",
    "cat_encoded = [onehot_encode(df[col].values) for col in cat_cols]\n",
    "cat_en = np.hstack(cat_encoded) if cat_encoded else np.array([])\n",
    "\n",
    "num_scaled = [minmax_scale(df[col].values) for col in num_cols]\n",
    "num_scaled = np.column_stack(num_scaled) if num_scaled else np.array([])\n",
    "\n",
    "# Собираем X\n",
    "if cat_en.size and num_scaled.size:\n",
    "    X = np.hstack([cat_en, num_scaled])\n",
    "elif cat_en.size:\n",
    "    X = cat_en\n",
    "else:\n",
    "    X = num_scaled\n",
    "\n",
    "# Целевая переменная\n",
    "y = df['Claim'].values\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y :\", y.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (63326, 204)\n",
      "y : (63326,)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный анализ и подготовка датасета часто помогают улучшить качество модели. Ниже представлено несколько идей преобразований. Вы можете применить одно или несколько из этих преобразований (а можете не применять), чтобы помочь будущей модели. \n",
    "\n",
    "1. Посмотрите на количественные признаки. Возможно, в некоторых признаках есть выбросы - значения, которые сильно выбиваются. Такие значения полезно удалять. Советуем присмотреться к колонке Duration)\n",
    "\n",
    "2. Можно заметить, что one hot encoding сильно раздувает количество столбцов. Радикальное решение - можно попробовать выбросить все категориальные признаки из датасета.\n",
    "\n",
    "3. Если все-таки оставляете категориальные признаки, то подумайте, как уменьшить количество столбцов после one hot encoding. Признаки с большим количеством значений (Duration - 149! разных стран) можно удалить или попробовать сгруппировать некоторые значения.\n",
    "\n",
    "4. Downsampling. Датасет достаточно большой, разница в классах огромная. Можно уменьшить число наблюдений с частым ответом."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T19:48:02.505920Z",
     "start_time": "2025-10-21T19:47:58.550847Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# downsampling\n",
    "mj = df[df['Claim'] == 0]\n",
    "mn = df[df['Claim'] == 1]\n",
    "\n",
    "mj_down = mj.sample(len(mn), random_state=42)\n",
    "mn_dowm = pd.concat([mj_down, mn]).reset_index(drop=True)\n",
    "\n",
    "def onehot_encode(arr):\n",
    "    uniques = list(set(arr))\n",
    "    mapping = {v: i for i, v in enumerate(uniques)}\n",
    "    res = np.zeros((len(arr), len(uniques)), dtype=int)\n",
    "    for i, v in enumerate(arr):\n",
    "        res[i, mapping[v]] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "cat_selected = []\n",
    "for c in cat_cols:\n",
    "    if df[c].nunique() <= 20:\n",
    "        cat_selected.append(c)\n",
    "    else:\n",
    "        top_values = df[c].value_counts().nlargest(10).index\n",
    "        df[c] = df[c].apply(lambda x: x if x in top_values else 'Other')\n",
    "        cat_selected.append(c)\n",
    "\n",
    "cat_encoded = [onehot_encode(df[c].values) for c in cat_selected]\n",
    "cat_encoded = np.hstack(cat_encoded) if cat_encoded else np.array([])\n",
    "\n",
    "#Масштабирование\n",
    "num_cols = [c for c in df.columns if df[c].dtype != 'object' and c != 'Claim']\n",
    "def minmax_scale(arr):\n",
    "    arr = np.array(arr, dtype=float)\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "num_scaled = [minmax_scale(df[c].values) for c in num_cols]\n",
    "num_scaled = np.column_stack(num_scaled) if num_scaled else np.array([])\n",
    "\n",
    "if cat_encoded.size and num_scaled.size:\n",
    "    X = np.hstack([cat_encoded, num_scaled])\n",
    "elif cat_encoded.size:\n",
    "    X = cat_encoded\n",
    "else:\n",
    "    X = num_scaled\n",
    "\n",
    "y = df['Claim'].values\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (63326, 51)\n",
      "y shape: (63326,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение линейной регрессии (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это задача классификации, но её можно решить с помощью линейной регрессии, если округлять предсказанный ответ до целого и выбирать ближайший по значению ответ из множества {0, 1}.\n",
    "\n",
    "Вынесите признак 'Claim' в вектор ответов и разделите датасет на обучающую и тестовую выборку в соотношении 80 к 20. Зафиксируйте random_state.\n",
    "\n",
    "**Подсказка:** быстро перевести Yes/No в 1/0 можно так - np.where(df['Claim'] == 'Yes', 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T19:51:26.226373Z",
     "start_time": "2025-10-21T19:51:26.205662Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "y = np.where(df['Claim'] == 'Yes', 1, 0)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col != 'Claim':\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    elif col != 'Claim':\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == 'object' and c != 'Claim']\n",
    "num_cols = [c for c in df.columns if df[c].dtype != 'object' and c != 'Claim']\n",
    "\n",
    "def onehot_encode(arr):\n",
    "    uniques = list(set(arr))\n",
    "    mapping = {v:i for i,v in enumerate(uniques)}\n",
    "    res = np.zeros((len(arr), len(uniques)), dtype=int)\n",
    "    for i, v in enumerate(arr):\n",
    "        res[i, mapping[v]] = 1\n",
    "    return res\n",
    "\n",
    "cat_encoded = [onehot_encode(df[c].values) for c in cat_cols]\n",
    "cat_encoded = np.hstack(cat_encoded) if cat_encoded else np.array([])\n",
    "\n",
    "def minmax_scale(arr):\n",
    "    arr = np.array(arr, dtype=float)\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "num_scaled = [minmax_scale(df[c].values) for c in num_cols]\n",
    "num_scaled = np.column_stack(num_scaled) if num_scaled else np.array([])\n",
    "\n",
    "if cat_encoded.size and num_scaled.size:\n",
    "    X = np.hstack([cat_encoded, num_scaled])\n",
    "elif cat_encoded.size:\n",
    "    X = cat_encoded\n",
    "else:\n",
    "    X = num_scaled\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_class = np.round(y_pred).astype(int)\n",
    "\n",
    "#Проверяем точность\n",
    "accuracy = (y_pred_class == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlinear_model\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LinearRegression\n\u001B[32m      7\u001B[39m url = \u001B[33m\"\u001B[39m\u001B[33mhttps://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel\u001B[39m\u001B[38;5;132;01m%20i\u001B[39;00m\u001B[33mnsurance.csv\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'sklearn'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите аналитическое решение для обучающей выборки: обычное и регуляризацией l2. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T20:01:23.344742Z",
     "start_time": "2025-10-21T20:01:23.332766Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_bias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m beta = np.linalg.inv(\u001B[43mX_bias\u001B[49m.T @ X_bias) @ X_bias.T @ y\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(beta)\n",
      "\u001B[31mNameError\u001B[39m: name 'X_bias' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитать аналитическое решение с регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель LinearRegression, примените к тестовой выборке и посчитайте MSE (можно использовать библиотеку sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "\n",
    "y = np.where(df['Claim'] == 'Yes', 1, 0)\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col != 'Claim':\n",
    "        df[col] = df[col].fillna('unknown')\n",
    "    elif col != 'Claim':\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "\n",
    "cat_cols = [c for c in df.columns if df[c].dtype == 'object' and c != 'Claim']\n",
    "num_cols = [c for c in df.columns if df[c].dtype != 'object' and c != 'Claim']\n",
    "\n",
    "def encode_cat(arr):\n",
    "    uniques = list(set(arr))\n",
    "    mapping = {v:i for i,v in enumerate(uniques)}\n",
    "    mat = np.zeros((len(arr), len(uniques)))\n",
    "    for i, v in enumerate(arr):\n",
    "        mat[i, mapping[v]] = 1\n",
    "    return mat\n",
    "\n",
    "cat_encoded = [encode_cat(df[c].values) for c in cat_cols]\n",
    "cat_encoded = np.hstack(cat_encoded) if cat_encoded else np.array([])\n",
    "\n",
    "\n",
    "def scale_num(arr):\n",
    "    arr = np.array(arr, dtype=float)\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "num_scaled = [scale_num(df[c].values) for c in num_cols]\n",
    "num_scaled = np.column_stack(num_scaled) if num_scaled else np.array([])\n",
    "\n",
    "if cat_encoded.size and num_scaled.size:\n",
    "    X = np.hstack([cat_encoded, num_scaled])\n",
    "elif cat_encoded.size:\n",
    "    X = cat_encoded\n",
    "else:\n",
    "    X = num_scaled\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error на тестовой выборке:\", mse)# посчитайте MSE, предварительно округлив предсказанные ответы до целого"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод (1 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Я заполнил пустые значения в числовых колонках средними, а в текстовых — пометкой 'unknown'. Категориальные признаки перевёл в числа, числовые масштабировал, чтобы всё было сопоставимо. Линейная модель предсказывает довольно неплохо, но так как это задача классификации, точность могла бы быть лучше, если бы использовались дополнительные метрики или методы балансировки классов."
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
